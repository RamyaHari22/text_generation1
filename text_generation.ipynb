{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "8uViTmQNpNBu",
        "outputId": "0bb9cd2b-779d-4ce8-be26-ead5511ea895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 6.965815544128418\n",
            "Random Seed:\n",
            "  spanclassgooglesymbolsnotranslatemuiiconrootmuiiconfontsizemediumscffetsbhohpunotranslatecss1jgtvd5ariahiddenfalsearialabelhidetreerolebuttontabindex0chevron_rightspandivspandivdivmodeviewclassschovstyjjqklsdivdivclasssckiismrigrcfkdivclasssceauhaascigwfco \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[-1, 100, 1]' is invalid for input of size 50",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f02db388eaf7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-f02db388eaf7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Seed:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_to_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-f02db388eaf7>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, chars, num_to_char, pattern, vocab_len)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 100, 1]' is invalid for input of size 50"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, x_data, y_data):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.x_data[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.y_data[idx], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        text = f.read()\n",
        "    return text\n",
        "\n",
        "def tokenize_words(text):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text.lower())\n",
        "    return tokens\n",
        "\n",
        "def convert_text_to_numbers(text, chars):\n",
        "    char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
        "    return [char_to_num[char] for char in text]\n",
        "\n",
        "def generate_text(model, chars, num_to_char, pattern, vocab_len):\n",
        "    for i in range(100):\n",
        "        x = torch.tensor(pattern, dtype=torch.float32).unsqueeze(0)\n",
        "        x = x.view(-1, 100, 1)\n",
        "        x = x / float(vocab_len)\n",
        "        prediction = model(x)\n",
        "        index = torch.argmax(prediction)\n",
        "        result = num_to_char[index.item()]\n",
        "        seq_in = [num_to_char[value] for value in pattern]\n",
        "        print(result, end=\"\")\n",
        "        pattern.append(index.item())\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "def main():\n",
        "    file_path = \"frankenstein.txt\"\n",
        "    text = load_data(file_path)\n",
        "    processed_inputs = tokenize_words(text)\n",
        "    chars = sorted(list(set(processed_inputs)))\n",
        "    vocab_len = len(chars)\n",
        "    char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
        "    num_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "    seq_length = 50\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    for i in range(0, len(processed_inputs) - seq_length, 1):\n",
        "        in_seq = processed_inputs[i:i + seq_length]\n",
        "        out_seq = processed_inputs[i + seq_length]\n",
        "        x_data.append([char_to_num[char] for char in in_seq])\n",
        "        y_data.append(char_to_num[out_seq])\n",
        "    dataset = TextDataset(x_data, y_data)\n",
        "    data_loader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "    class LSTMModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(LSTMModel, self).__init__()\n",
        "            self.lstm = nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
        "            self.dropout = nn.Dropout(0.2)\n",
        "            self.fc = nn.Linear(128, vocab_len)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = x.view(-1, 50, 1)\n",
        "            h0 = torch.zeros(1, x.size(0), 128).to(x.device)\n",
        "            c0 = torch.zeros(1, x.size(0), 128).to(x.device)\n",
        "            out, _ = self.lstm(x, (h0, c0))\n",
        "            out = self.dropout(out[:, -1, :])\n",
        "            out = self.fc(out)\n",
        "            return out\n",
        "\n",
        "    model = LSTMModel()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    for epoch in range(1):\n",
        "        for batch in data_loader:\n",
        "            inputs, labels = batch\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "    start = np.random.randint(0, len(x_data) - 1)\n",
        "    pattern = x_data[start]\n",
        "    print(\"Random Seed:\")\n",
        "    print(\" \", ''.join([num_to_char[value] for value in pattern]), \"\")\n",
        "    generate_text(model, chars, num_to_char, pattern, vocab_len)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}